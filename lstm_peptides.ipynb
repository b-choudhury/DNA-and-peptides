{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Input, concatenate, Reshape, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"peptides.txt\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names: 99\n",
      "Amount of names after removing those with unwanted characters\n",
      ": 99\n",
      "Using the following characters:\n",
      " [' ', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n"
     ]
    }
   ],
   "source": [
    "def process_names(names,*,unwanted=[]):\n",
    "    names = [name for name in names]\n",
    "    print(\"Total names:\",len(names))\n",
    "    chars = sorted(list(set(''.join(names))))\n",
    "\n",
    "    def has_unwanted(word):\n",
    "        for char in word:\n",
    "            if char in unwanted:\n",
    "                return True\n",
    "        return False\n",
    "    names = [name for name in names if not has_unwanted(name)]\n",
    "    print(\"Amount of names after removing those with unwanted characters\\n:\",len(names))\n",
    "    chars = [char for char in chars if char not in unwanted]\n",
    "    print(\"Using the following characters:\\n\",chars)\n",
    "\n",
    "\n",
    "\n",
    "    return names,chars\n",
    "\n",
    "\n",
    "names,chars = process_names(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584 sequences of length 4 made\n"
     ]
    }
   ],
   "source": [
    "def make_sequences(names,seqlen):\n",
    "    sequences, lengths, nextchars = [],[],[] # To have the model learn a more macro understanding, \n",
    "                                             # it also takes the word's length so far as input\n",
    "    for name in names:\n",
    "        if len(name) <= seqlen:\n",
    "            sequences.append(name + chars[-1]*(seqlen - len(name)))\n",
    "            nextchars.append(chars[-1])\n",
    "            lengths.append(len(name))\n",
    "        else:\n",
    "            for i in range(0,len(name)-seqlen+1):\n",
    "                sequences.append(name[i:i+seqlen])\n",
    "                if i+seqlen < len(name):\n",
    "                    nextchars.append(name[i+seqlen])\n",
    "                else:\n",
    "                    nextchars.append(chars[-1])\n",
    "                lengths.append(i+seqlen)\n",
    "\n",
    "    print(len(sequences),\"sequences of length\",seqlen,\"made\")\n",
    "    \n",
    "    return sequences,lengths,nextchars\n",
    "\n",
    "seqlen = 4\n",
    "sequences,lengths,nextchars = make_sequences(names,seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehots(*,sequences,lengths,nextchars,chars):\n",
    "    x = np.zeros(shape=(len(sequences),len(sequences[0]),len(chars)), dtype='float32') # sequences\n",
    "    x2 = np.zeros(shape=(len(lengths),max(lengths))) # lengths\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, char in enumerate(seq):\n",
    "            x[i,j,chars.index(char)] = 1.\n",
    "\n",
    "    for i, l in enumerate(lengths):\n",
    "        x2[i,l-1] = 1.\n",
    "\n",
    "    y = np.zeros(shape=(len(nextchars),len(chars)))\n",
    "    for i, char in enumerate(nextchars):\n",
    "        y[i,chars.index(char)] = 1.\n",
    "    \n",
    "    return x,x2,y\n",
    "\n",
    "x,x2,y = make_onehots(sequences=sequences,\n",
    "                     lengths=lengths,\n",
    "                     nextchars=nextchars,\n",
    "                     chars=chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictchars(names,seqlen):\n",
    "    dictchars = [{} for _ in range(seqlen)]\n",
    "\n",
    "    for name in names:\n",
    "        if len(name) < seqlen:\n",
    "            continue\n",
    "        dictchars[0][name[0]] = dictchars[0].get(name[0],0) + 1\n",
    "        for i in range(1,seqlen):\n",
    "            if dictchars[i].get(name[i-1],0) == 0:\n",
    "                dictchars[i][name[i-1]] = {name[i]: 1}\n",
    "            elif dictchars[i][name[i-1]].get(name[i],0) == 0:\n",
    "                dictchars[i][name[i-1]][name[i]] = 1\n",
    "            else:\n",
    "                dictchars[i][name[i-1]][name[i]] += 1\n",
    "    return dictchars\n",
    "                \n",
    "dictchars = get_dictchars(names,seqlen)\n",
    "                \n",
    "\n",
    "def generate_start_seq(dictchars):\n",
    "    res = \"\" # The starting sequence will be stored here\n",
    "    p = sum([n for n in dictchars[0].values()]) # total amount of letter occurences\n",
    "    r = np.random.randint(0,p) # random number used to pick the next character\n",
    "    tot = 0\n",
    "    for key, item in dictchars[0].items():\n",
    "        if r >= tot and r < tot + item:\n",
    "            res += key\n",
    "            break\n",
    "        else:\n",
    "            tot += item\n",
    "\n",
    "    for i in range(1,len(dictchars)):\n",
    "        ch = res[-1]\n",
    "        if dictchars[i].get(ch,0) == 0:\n",
    "            l = list(dictchars[i].keys())\n",
    "            ch = l[np.random.randint(0,len(l))]\n",
    "        p = sum([n for n in dictchars[i][ch].values()])\n",
    "        r = np.random.randint(0,p)\n",
    "        tot = 0\n",
    "        for key, item in dictchars[i][ch].items():\n",
    "            if r >= tot and r < tot + item:\n",
    "                res += key\n",
    "                break\n",
    "            else:\n",
    "                tot += item\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds,temperature=0.4):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    if temperature == 0:\n",
    "        # Avoiding a division by 0 error\n",
    "        return np.argmax(preds)\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_name(model,start,*,chars=chars,temperature=0.4):\n",
    "    maxlength = model.layers[3].input.shape[1]\n",
    "    seqlen = int(model.layers[0].input.shape[1])\n",
    "    result = start\n",
    "    \n",
    "    sequence_input = np.zeros(shape=(1,seqlen,len(chars)))\n",
    "    for i, char in enumerate(start):\n",
    "        sequence_input[0,i,chars.index(char)] = 1.\n",
    "    \n",
    "    length_input = np.zeros(shape=(1,maxlength))\n",
    "    length_input[0,len(result)-1] = 1.\n",
    "    \n",
    "    prediction = model.predict(x=[sequence_input,length_input])[0]\n",
    "    char_index = sample(prediction,temperature)\n",
    "    while char_index < len(chars)-1 and len(result) < maxlength:\n",
    "        result += chars[char_index]\n",
    "        \n",
    "        sequence_input = np.zeros(shape=(1,seqlen,len(chars)))\n",
    "        for i, char in enumerate(result[(-seqlen):]):\n",
    "            sequence_input[0,i,chars.index(char)] = 1.\n",
    "        \n",
    "        length_input[0,len(result)-2] = 0.\n",
    "        length_input[0,len(result)-1] = 1.\n",
    "        \n",
    "        prediction = model.predict(x=[sequence_input,length_input])[0]\n",
    "        char_index = sample(prediction,temperature)\n",
    "    \n",
    "    return result.title()\n",
    "\n",
    "def generate_random_name(model,*,chars=chars,dictchars=dictchars,temperature=0.4):\n",
    "    start = generate_start_seq(dictchars)\n",
    "    return generate_name(model,start,chars=chars,temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x,x2,chars):\n",
    "    inp1 = Input(shape=x.shape[1:]) # sequence input\n",
    "    inp2 = Input(shape=x2.shape[1:]) # length input\n",
    "    lstm = Bidirectional(LSTM(len(chars),activation='relu',dropout=0.3))(inp1)\n",
    "    lstm2 = Bidirectional(LSTM(len(chars),dropout=0.3,go_backwards=True))(inp1)\n",
    "    concat = concatenate([lstm,lstm2,inp2])\n",
    "    dense = Dense(len(chars),activation='softmax')(concat)\n",
    "\n",
    "    model = Model([inp1,inp2],dense)\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "model = make_model(x,x2,chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated=[]\n",
    "\n",
    "def try_model(model,*,x=x,x2=x2,y=y,chars=chars,dictchars=dictchars,total_epochs=180,print_every=1,temperature=0.4,verbose=True):\n",
    "    for i in range(total_epochs//print_every):\n",
    "        history = model.fit([x,x2],y,\n",
    "                            epochs=print_every,\n",
    "                            batch_size=64,\n",
    "                            validation_split=0.05,\n",
    "                            verbose=0)\n",
    "\n",
    "        generated.append((generate_random_name(model,chars=chars,dictchars=dictchars,temperature=temperature)).upper())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "file1 = open(\"generated.txt\",\"a\") \n",
    "try_model(model)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' AENKKFKLHAENKKFKLH',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AEILSGRVIAFNCTFE',\n",
       " ' AEALLADGLAEMRETHWL',\n",
       " ' ALFPFWLT',\n",
       " ' AIQIQMFEAALSFGLS',\n",
       " ' AADLLFFLLAISKLRFRS',\n",
       " ' ALASFLFGFALFLFWLVW',\n",
       " ' AEHLENQVLAEFERGVGI',\n",
       " ' AAVDLSHFLAERGPGQML',\n",
       " ' AENGWGF',\n",
       " ' AIHPFALLLAISRLRTQK',\n",
       " ' AIDTIKSL',\n",
       " ' AEILSGRVIAEILSGRVI',\n",
       " ' AAGLPAIFVAAGLPAIFV',\n",
       " ' AIHPFALLLAIITSILTK',\n",
       " ' AIKPITDQFAIKSVFNSL',\n",
       " ' AIQRQMLEAALS',\n",
       " ' AAFLDDNAFAAALADAGF',\n",
       " ' AENGWGF',\n",
       " ' AASCGGAVFAASLFFDWP',\n",
       " ' AFLIGAN',\n",
       " ' AEALLADGLAEFPVGSTA',\n",
       " ' AIPGF',\n",
       " ' AFLIGAN',\n",
       " ' AHSKAETEAAHSKAETEA',\n",
       " ' ADAGFMKQ',\n",
       " ' AEKSRGRRIAEKSRGRRI',\n",
       " ' AIP',\n",
       " ' AEKSRGRRIAEILSGRVI',\n",
       " ' AEFPVGSTAAEFPVGSTA',\n",
       " ' AFLDDNAF',\n",
       " ' AFDPVWATF',\n",
       " ' AIPGF',\n",
       " ' ALGIICSALAHARFVAAS',\n",
       " ' AGITTQQMLAERGPGQML',\n",
       " ' AADKAAAAAAAAALAAAL',\n",
       " ' ADAGFMKQ',\n",
       " ' AIFQSSMTKAIFQSSMTK',\n",
       " ' ALMKATAEMAIID',\n",
       " ' AELETGVGFALFDRPAFK',\n",
       " ' AADKAAAAAAAAAAAAAA',\n",
       " ' AGIDN',\n",
       " ' AGFVAGLT',\n",
       " ' AFASLQDMLAFADRAFSF',\n",
       " ' AINGFVLPKAINGFVLPK',\n",
       " ' AFLIGAN',\n",
       " ' AEFPVGSTAAEFPVGSTA',\n",
       " ' AERGPGQMLAERGPGQML',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AEGWDNFLFALGIICSAL',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' ACREQQLPVACREQQLPV',\n",
       " ' AIID',\n",
       " ' ALFHKVQS',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AERGPGQMLAERGPGQML',\n",
       " ' AFASLQDMLAFADKAAAA',\n",
       " ' AISDPCMGLAEAGLS',\n",
       " ' ALIDGLVVIAHSRFWS',\n",
       " ' AAGLT',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AIDFLLQRWAIDFLLQRW',\n",
       " ' AHGWSTF',\n",
       " ' AHSKAETEAAHSKAETEA',\n",
       " ' AILGVLATLAIHPFALLL',\n",
       " ' AENGWGF',\n",
       " ' ALFHKVQS',\n",
       " ' AEDMLNPN',\n",
       " ' AISDPCMGLAISKPATEF',\n",
       " ' AEILSGRVIAFRIVAATL',\n",
       " ' ALFHKVQS',\n",
       " ' AINGFVLPKAINGFVLPK',\n",
       " ' ADAGFMKQ',\n",
       " ' AGFPTGLT',\n",
       " ' AINGFVLPKAINGFVLPK',\n",
       " ' AITTSNCAKAIARLVQVL',\n",
       " ' AKSVFNSL',\n",
       " ' AANEIRISKAATEEMLNP',\n",
       " ' ADFKLFFRWADFKLFFRW',\n",
       " ' AIDFLLQRWAIDFLLQRW',\n",
       " ' AGRAWENTIAGRAWENTI',\n",
       " ' AADKAAAAAAAAAAAAAL',\n",
       " ' AAILKQHKLAAILKQHKL',\n",
       " ' AGFTAGLT',\n",
       " ' AEIDRSFKPAEIDRSFKP',\n",
       " ' ALGIICSALAKATGR',\n",
       " ' ALIGGVAELADGLFWLVW',\n",
       " ' AHGWSTF',\n",
       " ' AFRDVLVVLAFRDVLVVL',\n",
       " ' AANEIRISKAAAAAAAAV',\n",
       " ' AIID',\n",
       " ' AGFTAGLS',\n",
       " ' AFNCTFE',\n",
       " ' AGFTAGLT',\n",
       " ' ALFHKVQS',\n",
       " ' AEKSRGRRIAEKSRGRRI',\n",
       " ' AKSVFNSL',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AIFQSSMTKAITTPQMTL',\n",
       " ' AANEIRISKAATEEMLT',\n",
       " ' AERGPGQMLAERGPGQML',\n",
       " ' ADFKLFFRWADFKLFFRW',\n",
       " ' ALLADGLT',\n",
       " ' ACREQQLPVACREQQLPV',\n",
       " ' AFLIGAN',\n",
       " ' ALLIICSALAGNHWHVVL',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AGSK',\n",
       " ' ALEPGFKD',\n",
       " ' AEILSGRVIAEILSGRVI',\n",
       " ' AADKAAAAAAAAAAAAAA',\n",
       " ' AIQIQMFEAALLDDNAFK',\n",
       " ' AIID',\n",
       " ' ALFHKVQS',\n",
       " ' ALASFLFGFALASFLFGF',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' ALEPGFKD',\n",
       " ' ALASFLFGFALGIICSAL',\n",
       " ' AENGWGF',\n",
       " ' AHIDN',\n",
       " ' AEDMLNPN',\n",
       " ' AFLDDNAF',\n",
       " ' AIQIQMFEAADSFATS',\n",
       " ' AFLLFLVLIAFLLFLVLI',\n",
       " ' AFGLFWLVWAFGLFWLVW',\n",
       " ' AAVDLSHFLAERGPGQML',\n",
       " ' AEDMLNPN',\n",
       " ' AAVDLSHFLAERGPGQML',\n",
       " ' ALAGNHWHVALAGNHWHV',\n",
       " ' AFGLFWLVWAFGLFWLVW',\n",
       " ' AAKKKGASLAFEKMVSLL',\n",
       " ' AIKPITDQFAIKPITDQF',\n",
       " ' ALAGNHWHVALAKAAAAK',\n",
       " ' ALAAAAAAKALAAAAAAK',\n",
       " ' ALIDGLVVLAFRDVLVVL',\n",
       " ' AAKALAAALAAAAAAAAK',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AENGWGF',\n",
       " ' AGIDN',\n",
       " ' AFIDTIKSLAFNSL',\n",
       " ' AGS',\n",
       " ' ACREQQLPVACREQQLPV',\n",
       " ' AGFTAGLS',\n",
       " ' AGRAWENTIAGRAWENTI',\n",
       " ' AGRAWENTIAGRAWENTI',\n",
       " ' AGFVAGLT',\n",
       " ' AARISSCLKAAGRAWENT',\n",
       " ' AGFTAGLT',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AAFLDDNAFAAALAAAAA',\n",
       " ' ALASFLFGFALASFLFGF',\n",
       " ' ALLADGLFVALLLDGLVV',\n",
       " ' AIDRISSCLAGATEEMVV',\n",
       " ' AEKSRGRRIAEKSRGRRI',\n",
       " ' ALEPGFKD',\n",
       " ' AFDIASVFFAFDIASVFF',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AIFQSSMTKAIFQSSMTK',\n",
       " ' ALFHKVQS',\n",
       " ' AITTPQMTLAILGVLATL',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AIP',\n",
       " ' ALMKTDAATAEMKTDAAT',\n",
       " ' AFLIGAN',\n",
       " ' AARISSCLKAAAAAAAAA',\n",
       " ' ALMKTDAATAEMKTDAAT',\n",
       " ' AGFPTGLT',\n",
       " ' AADKAAAAAAAAAAAAAK',\n",
       " ' AFEKMVSLLAFEDMRN',\n",
       " ' ALASFLFGFALASFLFGF',\n",
       " ' AEMRETHWLAEMRETHWL',\n",
       " ' AAILGVLATAEMLTIITH',\n",
       " ' AFDIASVFFAFDIASVFF',\n",
       " ' AIKPITDQFAIKPITDQF',\n",
       " ' AAKKKGASLAFHKPAERW',\n",
       " ' AFASLQDMLAFASLQDML',\n",
       " ' ADLRFASEFADDRAAFEK',\n",
       " ' AEGTGITHLAEGTGITHL',\n",
       " ' AIID']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('generated.txt',generated, delimiter=\" \", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
